<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="styles.css" type="text/css" />
</head>
<body>
<div class="topNav">
<ul class="navList"><li class="navBarCell1Rev">
<a href="overview-summary.html">Overview</a>
</li></ul>
<div class="aboutLanguage">
<em>SDK version 2.0.2</em>
</div>
</div>
<div class="subNav"><ul class="navList"><li>
<a href="Transition-EventEngineExampleApp.html">Prev</a>
</li><li>
<a href="How%20to%20Build%20&%20Test%20a%20Decoder%20Plugin.html">Next</a>
</li></ul></div>
<h1 id="intrasonics-decoder-plugin-integration">Intrasonics Decoder Plugin Integration</h1>
<p>Advanced users of the SDK can create their own plugins (audio processors) which can process and decode audio alongside Intrasonics own decoder. The Plugin Engine reports data generated by such plugins to the engine delegate along with the absolute time the data was decoded.</p>
<p>Further details, and an example project that uses the Plugin Engine, can be found <a href="PluginEngine%20Example%20Project.html">here</a>. To learn how to develop plugins for the Decoder framework, contact Intrasonics to get access to the Decoder Plugin SDK.</p>
<h2 id="handset-architecture">Handset Architecture</h2>
<p>The Intrasonics Decoder architecture is as shown below;</p>
<center>
<img alt="Decoder Plugin Architecture 1" src="images/Decoder Plugin Architecture_1.png" width="500"/>
</center>

<h2 id="integration-process-for-android">Integration Process for Android</h2>
<p>Developers can build and test their plug-ins as C++ .so libraries. The low-level AudioDecoder will automatically search for plugin libraries, load them and initialise them at the appropriate time. To make a plugin available to the framework, it needs to be placed in the libs directory of the containing app when compiling and packaging the app.</p>
<p>Sometimes an app will need to set up files for use by a plugin. The framework assigns a dedicated folder to each plugin which can be retrieved at the app level (and is communicated to the plugin when it starts);</p>
<pre><code>String pluginPath = mDecoder.getFilePathForPlugin(&quot;intrasonics_TestPlugin&quot;);</code></pre>
<h2 id="power-and-processor-implications">Power and Processor Implications:</h2>
<p>Additional plugins will consume additional processor and power resources on the handsets partly due to the extra CPU from processing multiple buffers, the overhead of the extra plugin itself and any necessary audio sample rate conversion.</p>
<h2 id="handset-integration-interface">Handset Integration Interface:</h2>
<h3 id="architecture">Architecture</h3>
<p>The Audio Decoder provides a generic interface for AudioProcessor plugins. The interface is defined in C++ â€™11 as header files, which the audio processor plugin developer can build their library against.</p>
<center>
<img alt="Decoder Plugin Architecture 2" src="images/Decoder Plugin Architecture_2.png" width="500"/>
</center>

<p>Each AudioProcessor plugin is informed when the Decoder starts and stops through the <code>IAudioProcessor::Start</code> and <code>IAudioProcessor::Stop</code> methods. No samples are sent to the AudioProcessor while it is stopped.</p>
<p>Samples are sent to each AudioProcessor in turn as buffers. Audio buffers will be a multiple of 1024 samples long (1x if sampling at 8kHz). Audio will be captured at 16bit PCM mono. The sample rate is determined by querying each plugin for their required sample rate and determining an appropriate rate to record at. Audio is then resampled (if it can be) to match the plugins' requirements. See <code>ISampleRateAdviser</code> for more information.</p>
<h3 id="object-lifetime">Object Lifetime</h3>
<p>In general:</p>
<ul>
<li>All objects passed as parameters in a method call are assumed to be owned by the calling object and are therefore only guaranteed for the lifetime of the call.</li>
<li>All objects returned by a method call are assumed to be owned by the object which called the method.</li>
</ul>
<h3 id="startup">Startup</h3>
<p>On Android when the AudioDecoder starts up it checks the file system for included plugin shared object libraries and loads them if it can:</p>
<ul>
<li>The AudioDecoder creates the plugin by calling <code>CreateAudioProcessor()</code> on Android.</li>
<li>The AudioDecoder asks the AudioProcessor for its name and version and reports this in the Log.</li>
<li>If the AudioProcessor implements the <code>ISampleRateAdviser</code> interface, the framework queries this interface and sets up recording to support the sample rate if it can (see <code>ISampleRateAdviser</code> for more information).</li>
<li>The AudioDecoder sets up the AudioProcessor with other internal information.</li>
</ul>
<h3 id="plugin-decoded-data-communication">Plugin Decoded Data Communication</h3>
<p>Two methods of reporting data to the app level from the plugin are supported; event based and polled. In general an AudioProcessor used with the SDK in a consumer-oriented app should use event-based data reporting;</p>
<center>
<img alt="Decoder Plugin Architecture 3" src="images/Decoder Plugin Architecture_3.png" width="500"/>
</center>

When the audio processor detects information it should initiate an event to transmit the data up to the app through the <code>IAudioProcessorListener::onProcessorEvent</code> method. The polling scheme is provided for audio processors which require timed updates and, in general, should not be used by AudioProcessors which need to work with the standard SDK. Several implementations of <code>IProcessorEventParams</code> can be used to return data to the app level from an audio processor. In general the <code>DictionaryEventParams</code> is most suited to audio processors for the standard SDK. Data provided in this way will be returned through the <code>AudioProcessorEngine</code>.
<div class="bottomNav">
<ul class="navList"><li class="navBarCell1Rev">
<a href="overview-summary.html">Overview</a>
</li></ul>
<div class="aboutLanguage">
<em>SDK version 2.0.2</em>
</div>
</div>
<div class="subNav"><ul class="navList"><li>
<a href="Transition-EventEngineExampleApp.html">Prev</a>
</li><li>
<a href="How%20to%20Build%20&%20Test%20a%20Decoder%20Plugin.html">Next</a>
</li></ul></div>
</body>
</html>
